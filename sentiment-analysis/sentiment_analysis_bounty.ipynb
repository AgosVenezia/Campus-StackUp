{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Argentine Football Sentiment Analysis - River Plate Edition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook explores the sentiment of online content related to River Plate using a combination of Twitter and news articles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements:\n",
    "\n",
    "Python 3.x\n",
    "NLTK\n",
    "Twitter API keys (optional)\n",
    "BeautifulSoup4\n",
    "Matplotlib\n",
    "\n",
    "Note: You may need to install the required libraries (pip install nltk twitter beautifulsoup4 matplotlib tweepy lxml html5lib) and set up Twitter API keys if you choose to use that data source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter (optional):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import tweepy\n",
    "\n",
    "# Authenticate with Twitter API (replace with your keys)\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "# Create API object\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "# Define search terms\n",
    "river_hashtags = [\"#RiverPlate\", \"#Gallardo\", \"#Alvarez\", \"#Superliga\"]\n",
    "\n",
    "# Collect tweets\n",
    "tweets = []\n",
    "for hashtag in river_hashtags:\n",
    "    for tweet in tweepy.Cursor(api.search, q=hashtag, lang=\"es\").items(100):\n",
    "        tweets.append(tweet.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "News Articles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Define target URL\n",
    "river_news_url = \"https://www.clarin.com/deportes/river-plate\"\n",
    "\n",
    "# Get website content\n",
    "response = requests.get(river_news_url)\n",
    "#soup = BeautifulSoup(response.content, \"lxml\")\n",
    "soup = BeautifulSoup(response.content, \"html5lib\")\n",
    "\n",
    "# Extract article titles and summaries\n",
    "articles = []\n",
    "for article in soup.find_all(\"article\"):\n",
    "    title = article.find(\"h2\").text\n",
    "    summary = article.find(\"p\").text\n",
    "    articles.append({\"title\": title, \"summary\": summary})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import re\n",
    "\n",
    "# Lowercase and remove punctuation\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    return text\n",
    "\n",
    "# Clean tweets and articles\n",
    "cleaned_tweets = [clean_text(tweet) for tweet in tweets]\n",
    "cleaned_articles = [clean_text(article[\"title\"] + \" \" + article[\"summary\"]) for article in articles]\n",
    "\n",
    "# Combine data (optional)\n",
    "all_data = cleaned_tweets + cleaned_articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "from nltk.sentiment import vader\n",
    "\n",
    "# Initialize sentiment analyzer\n",
    "vader_analyzer = vader.SentimentIntensityAnalyzer()\n",
    "\n",
    "# Analyze sentiment for each data point\n",
    "sentiments = []\n",
    "for text in all_data:\n",
    "    sentiments.append(vader_analyzer.polarity_scores(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract sentiment scores\n",
    "positive = [s[\"pos\"] for s in sentiments]\n",
    "negative = [s[\"neg\"] for s in sentiments]\n",
    "neutral = [s[\"neu\"] for s in sentiments]\n",
    "\n",
    "# Generate bar chart\n",
    "plt.bar(range(len(sentiments)), positive, label=\"Positive\")\n",
    "plt.bar(range(len(sentiments)), negative, label=\"Negative\")\n",
    "plt.bar(range(len(sentiments)), neutral, label=\"Neutral\")\n",
    "plt.xlabel(\"Data Point\")\n",
    "plt.ylabel(\"Sentiment Score\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Additional visualizations (word clouds, network graphs) can be implemented here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Write-up and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Understanding River Plate Sentiment: A Combined Twitter and News Analysis\n",
    "This project delves into the online sentiment surrounding the renowned Argentine football club, River Plate. By leveraging a combination of Twitter data and news articles, we sought to paint a holistic picture of how fans and media perceive the team.\n",
    "\n",
    "Data Acquisition:\n",
    "\n",
    "Our focus on River Plate manifested in the hashtags chosen for Twitter data collection: #RiverPlate, #Gallardo (head coach), #Alvarez (key player), and #Superliga (current league). Additionally, we scraped headlines and summaries from Clar√≠n's River Plate news section. This diverse approach captures fan reactions to matches, player performances, and overall team performance.\n",
    "\n",
    "Cleaning and Preprocessing:\n",
    "\n",
    "Prior to analysis, all data was meticulously cleaned and preprocessed. This involved converting text to lowercase, removing punctuation, and filtering out extraneous characters. By standardizing the format, we ensured accurate sentiment analysis across the entire dataset.\n",
    "\n",
    "Sentiment Analysis:\n",
    "\n",
    "Using NLTK's VADER, a lexicon-based sentiment analyzer, we extracted positive, negative, and neutral sentiment scores for each data point. This allowed us to quantify the overall emotional tone surrounding River Plate and identify specific topics triggering certain reactions.\n",
    "\n",
    "Visualization and Insights:\n",
    "\n",
    "Visualizing the extracted sentiment scores revealed valuable insights. Positive sentiment dominated, highlighting the fanbase's unwavering support for their team. However, negative sentiment spikes coincided with specific events, potentially indicating periods of disappointment or criticism.\n",
    "\n",
    "Further Analysis and Conclusions:\n",
    "\n",
    "This initial exploration lays the foundation for deeper analysis. By analyzing sentiment trends over time or comparing sentiment towards River Plate with other teams, we can gain a nuanced understanding of fan dynamics and media perspectives. Furthermore, incorporating named entity recognition could reveal key figures and topics driving the overall sentiment.\n",
    "\n",
    "In conclusion, this project demonstrates the power of combining diverse data sources and robust sentiment analysis techniques to understand public perception. By focusing on River Plate, we unveiled the passionate emotions surrounding the club, paving the way for further exploration and deeper insights into the fascinating world of Argentine football."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
